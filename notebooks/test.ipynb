{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 341) (256, 341)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "img = np.load(\"/home/nics/Work/sp-sold2/assets/img/img_origin.npy\")\n",
    "warped_img = np.load(\"/home/nics/Work/sp-sold2/assets/img/img_warped.npy\")\n",
    "pts = np.load(\"/home/nics/Work/sp-sold2/assets/img/points_origin.npy\")\n",
    "warped_pts = np.load(\"/home/nics/Work/sp-sold2/assets/img/points_warped.npy\")\n",
    "h = np.load(\"/home/nics/Work/sp-sold2/assets/img/homo.npy\")\n",
    "from utils.superpoint import SuperPointFrontend\n",
    "from skimage import color \n",
    "\n",
    "weights_path = \"/home/nics/Work/SuperPointPretrainedNetwork/superpoint_v1.pth\"\n",
    "nms_dist = 4\n",
    "conf_thresh = 0.015\n",
    "nn_thresh = 0.7\n",
    "cuda = True\n",
    "fe = SuperPointFrontend(weights_path=weights_path,\n",
    "                          nms_dist=nms_dist,\n",
    "                          conf_thresh=conf_thresh,\n",
    "                          nn_thresh=nn_thresh,\n",
    "                          cuda=cuda)\n",
    "grayim1 = color.rgb2gray(img).astype(np.float32)\n",
    "grayim2 = warped_img/255.\n",
    "# print(grayim2.shape)\n",
    "# print(grayim.shape)\n",
    "pts1, desc1, _ = fe.run(grayim1)\n",
    "pts2, desc2, _ = fe.run(grayim2)\n",
    "print(pts2.shape, desc2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 349) (256, 349)\n"
     ]
    }
   ],
   "source": [
    "from utils.superpoint import SuperPointFrontend\n",
    "from skimage import color \n",
    "\n",
    "weights_path = \"/home/nics/Work/SuperPointPretrainedNetwork/superpoint_v1.pth\"\n",
    "nms_dist = 4\n",
    "conf_thresh = 0.015\n",
    "nn_thresh = 0.7\n",
    "cuda = True\n",
    "fe = SuperPointFrontend(weights_path=weights_path,\n",
    "                          nms_dist=nms_dist,\n",
    "                          conf_thresh=conf_thresh,\n",
    "                          nn_thresh=nn_thresh,\n",
    "                          cuda=cuda)\n",
    "grayim = color.rgb2gray(img).astype(np.float32)\n",
    "# print(grayim.shape)\n",
    "pts, desc, _ = fe.run(grayim)\n",
    "print(pts.shape, desc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_points(points, homographies, device='cpu'):\n",
    "    \"\"\"\n",
    "    Warp a list of points with the given homography.\n",
    "\n",
    "    Arguments:\n",
    "        points: list of N points, shape (N, 2(x, y))).\n",
    "        homography: batched or not (shapes (B, 3, 3) and (...) respectively).\n",
    "\n",
    "    Returns: a Tensor of shape (N, 2) or (B, N, 2(x, y)) (depending on whether the homography\n",
    "            is batched) containing the new coordinates of the warped points.\n",
    "\n",
    "    \"\"\"\n",
    "    # expand points len to (x, y, 1)\n",
    "    no_batches = len(homographies.shape) == 2\n",
    "    homographies = homographies.unsqueeze(0) if no_batches else homographies\n",
    "    # homographies = homographies.unsqueeze(0) if len(homographies.shape) == 2 else homographies\n",
    "    batch_size = homographies.shape[0]\n",
    "    points = torch.cat((points.float(), torch.ones((points.shape[0], 1)).to(device)), dim=1)\n",
    "    points = points.to(device)\n",
    "    homographies = homographies.view(batch_size*3,3).float()\n",
    "    # warped_points = homographies*points\n",
    "    # points = points.double()\n",
    "    warped_points = homographies@points.transpose(0,1)\n",
    "    # warped_points = np.tensordot(homographies, points.transpose(), axes=([2], [0]))\n",
    "    # normalize the points\n",
    "    warped_points = warped_points.view([batch_size, 3, -1])\n",
    "    warped_points = warped_points.transpose(2, 1)\n",
    "    warped_points = warped_points[:, :, :2] / warped_points[:, :, 2:]\n",
    "    return warped_points[0,:,:] if no_batches else warped_points\n",
    "\n",
    "# put to gpu\n",
    "homographies = h.to(device)\n",
    "# config\n",
    "from utils.utils import warp_points\n",
    "lamda_d = lamda_d # 250\n",
    "margin_pos = 1\n",
    "margin_neg = 0.2\n",
    "batch_size, Hc, Wc = descriptors.shape[0], descriptors.shape[2], descriptors.shape[3]\n",
    "#####\n",
    "# H, W = Hc.numpy().astype(int) * cell_size, Wc.numpy().astype(int) * cell_size\n",
    "H, W = Hc * cell_size, Wc * cell_size\n",
    "#####\n",
    "with torch.no_grad():\n",
    "    # shape = torch.tensor(list(descriptors.shape[2:]))*torch.tensor([cell_size, cell_size]).type(torch.FloatTensor).to(device)\n",
    "    shape = torch.tensor([H, W]).type(torch.FloatTensor).to(device)\n",
    "    # compute the center pixel of every cell in the image\n",
    "\n",
    "    coor_cells = torch.stack(torch.meshgrid(torch.arange(Hc), torch.arange(Wc)), dim=2)\n",
    "    coor_cells = coor_cells.type(torch.FloatTensor).to(device)\n",
    "    coor_cells = coor_cells * cell_size + cell_size // 2\n",
    "    ## coord_cells is now a grid containing the coordinates of the Hc x Wc\n",
    "    ## center pixels of the 8x8 cells of the image\n",
    "\n",
    "    # coor_cells = coor_cells.view([-1, Hc, Wc, 1, 1, 2])\n",
    "    coor_cells = coor_cells.view([-1, 1, 1, Hc, Wc, 2])  # be careful of the order\n",
    "    # warped_coor_cells = warp_points(coor_cells.view([-1, 2]), homographies, device)\n",
    "    warped_coor_cells = normPts(coor_cells.view([-1, 2]), shape)\n",
    "    warped_coor_cells = torch.stack((warped_coor_cells[:,1], warped_coor_cells[:,0]), dim=1) # (y, x) to (x, y)\n",
    "    warped_coor_cells = warp_points(warped_coor_cells, homographies, device)\n",
    "\n",
    "    warped_coor_cells = torch.stack((warped_coor_cells[:, :, 1], warped_coor_cells[:, :, 0]), dim=2)  # (batch, x, y) to (batch, y, x)\n",
    "\n",
    "    shape_cell = torch.tensor([H//cell_size, W//cell_size]).type(torch.FloatTensor).to(device)\n",
    "    # warped_coor_mask = denormPts(warped_coor_cells, shape_cell)\n",
    "\n",
    "    warped_coor_cells = denormPts(warped_coor_cells, shape)\n",
    "    # warped_coor_cells = warped_coor_cells.view([-1, 1, 1, Hc, Wc, 2])\n",
    "    warped_coor_cells = warped_coor_cells.view([-1, Hc, Wc, 1, 1, 2])\n",
    "#     print(\"warped_coor_cells: \", warped_coor_cells.shape)\n",
    "    # compute the pairwise distance\n",
    "    cell_distances = coor_cells - warped_coor_cells\n",
    "    cell_distances = torch.norm(cell_distances, dim=-1)\n",
    "    ##### check\n",
    "#     print(\"descriptor_dist: \", descriptor_dist)\n",
    "    mask = cell_distances <= descriptor_dist # 0.5 # trick\n",
    "\n",
    "    mask = mask.type(torch.FloatTensor).to(device)\n",
    "\n",
    "# compute the pairwise dot product between descriptors: d^t * d\n",
    "descriptors = descriptors.transpose(1, 2).transpose(2, 3)\n",
    "descriptors = descriptors.view((batch_size, Hc, Wc, 1, 1, -1))\n",
    "descriptors_warped = descriptors_warped.transpose(1, 2).transpose(2, 3)\n",
    "descriptors_warped = descriptors_warped.view((batch_size, 1, 1, Hc, Wc, -1))\n",
    "dot_product_desc = descriptors * descriptors_warped\n",
    "dot_product_desc = dot_product_desc.sum(dim=-1)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
